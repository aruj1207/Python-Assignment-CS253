{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOw67GCPPYqpbVfHOQTwlYN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aruj1207/ACAha1/blob/main/Python%20Assignment%20Code\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IE-vQLGJNw0Y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# for cross validation accuracy\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# other libraries tried but not used\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# For improving my accuracy using different parameters checked through Grid Search\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import svm\n",
        "\n",
        "#Loading datasets\n",
        "train_df = pd.read_csv('/content/train.csv')\n",
        "test_df = pd.read_csv('/content/test.csv')\n",
        "\n",
        "#Handling missing values if any\n",
        "train_df=train_df.dropna(axis=0)\n",
        "test_df=test_df.dropna(axis=0)"
      ],
      "metadata": {
        "id": "NnXT8crtNNXH"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# as ID and name are different for all there is no point inculding that to predict education\n",
        "features = ['Party', 'Criminal Case', 'Total Assets', 'Liabilities', 'state']\n",
        "columns_to_encode = ['Party', 'state']\n",
        "\n",
        "# different encoder to maintain consistency in encoding and prevents data leakage\n",
        "label_encoders = {}\n",
        "\n",
        "#Encoding categorical columns\n",
        "for col in columns_to_encode:\n",
        "    label_encoders[col] = LabelEncoder()\n",
        "    train_df[col + '_encoded_into_numeric'] = label_encoders[col].fit_transform(train_df[col])\n",
        "\n",
        "#encoded and non-encoded columns\n",
        "encoded_columns = [col + '_encoded_into_numeric' for col in columns_to_encode]\n",
        "not_encoded_columns = [col for col in features if col not in columns_to_encode]\n",
        "\n",
        "# Update feature matrix with encoded columns\n",
        "X = train_df[not_encoded_columns + encoded_columns]\n",
        "\n",
        "#function to omit values save in Alpha-numeral format\n",
        "def extract_numerical_value(asset_str):\n",
        "    if 'Crore' in asset_str:\n",
        "        return int(float(asset_str.replace('Crore+', '')) * 10000000)  # Convert Crore to numerical value\n",
        "    elif 'Lac' in asset_str:\n",
        "        return int(float(asset_str.replace('Lac+', '')) * 100000)  # Convert Lakh to numerical value\n",
        "    elif 'Thou' in asset_str:\n",
        "        return int(float(asset_str.replace('Thou+', '')) * 1000)   # Convert Thousand to numerical value\n",
        "    elif 'Hund' in asset_str:\n",
        "        return int(float(asset_str.replace('Hund+', '')) * 100)   # Convert Hundred to numerical value\n",
        "    else:\n",
        "        return 0  # For direct values\n",
        "\n",
        "#replacing colums with entire numerical value\n",
        "X['Total Assets'] = X['Total Assets'].apply(extract_numerical_value)\n",
        "X['Liabilities']=X['Liabilities'].apply(extract_numerical_value)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "Y = label_encoder.fit_transform(train_df['Education'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfCZwQAuz0vz",
        "outputId": "16296c12-ce87-4573-8434-1796924c7359"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-f32592c63386>:34: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['Total Assets'] = X['Total Assets'].apply(extract_numerical_value)\n",
            "<ipython-input-2-f32592c63386>:35: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['Liabilities']=X['Liabilities'].apply(extract_numerical_value)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# there are many different parameters we can set for different models to get the best f1 score and precision\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200,300,400,500],\n",
        "    'max_depth': [10,15,17,21],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "\n",
        "}\n",
        "#Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5)\n",
        "\n",
        "#Fit the grid search\n",
        "grid_search.fit(X,Y)\n",
        "\n",
        "#the best parameters\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Parameters:\", best_params)"
      ],
      "metadata": {
        "id": "vc6Mobze6SSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Module used for prediction\n",
        "\n",
        "# model = RandomForestClassifier()\n",
        "#0.202\n",
        "\n",
        "# model = RandomForestClassifier(n_estimators=300)\n",
        "#0.200\n",
        "\n",
        "# model = RandomForestClassifier(max_depth=17,min_samples_split=3,n_estimators=550)\n",
        "#.22\n",
        "# model = RandomForestClassifier(max_depth=17,min_samples_split=3,n_estimators=550)\n",
        "#0.219\n",
        "\n",
        "# model = RandomForestClassifier(max_depth=17,min_samples_split=3,n_estimators=750)\n",
        "#0.217\n",
        "\n",
        "# model = RandomForestClassifier(max_depth=11,min_samples_split=3,n_estimators=400)\n",
        "#0.237\n",
        "#badhiyaaa\n",
        "\n",
        "# model = RandomForestClassifier(max_depth=7,min_samples_split=3,n_estimators=400)\n",
        "#0.2627\n",
        "\n",
        "# model = RandomForestClassifier(max_depth=3,min_samples_split=3,n_estimators=400)\n",
        "#0.2583\n",
        "\n",
        "# model = RandomForestClassifier(max_depth=5,min_samples_split=3,n_estimators=400)\n",
        "#highest\n",
        "#0.268\n",
        "\n",
        "#model = RandomForestClassifier(max_depth=5, min_samples_leaf= 1, min_samples_split= 5, n_estimators= 300)\n",
        "#0.2647\n",
        "\n",
        "\n",
        "# model = KNeighborsClassifier(n_neighbors=59)\n",
        "#Highest\n",
        "#0.2413\n",
        "# manhattan , 0.2340\n",
        "#brute = 0.2408\n",
        "\n",
        "\n",
        "# model= KNeighborsClassifier( n_neighbors= 11)\n",
        "# test ki dhol\n",
        "\n",
        "# 0.33980582524271846\n",
        "\n",
        "\n",
        "# 0.17161782624284022\n",
        "# train\n",
        "\n",
        "# 0.3393782383419689\n",
        "\n",
        "\n",
        "# 0.16958404904013674\n",
        "# model = SVC(C=5)\n",
        "\n",
        "# depth 17 nst matter 350 , msplit 3 ,\n",
        "# model = RandomForestClassifier(max_depth=17,min_samples_split=3,n_estimators=350)\n",
        "# test ki dhol\n",
        "\n",
        "# 0.9495145631067962\n",
        "\n",
        "\n",
        "# 0.9242578116862056\n",
        "# train\n",
        "\n",
        "# 0.9617875647668394\n",
        "\n",
        "\n",
        "# 0.9643738541019745\n",
        "# model = RandomForestClassifier(max_depth=17,min_samples_split=7,n_estimators=550)\n",
        "X_train,X_val,y_train, y_val=train_test_split(X,Y)\n",
        "# model = RandomForestClassifier(max_depth=17,min_samples_split=2,n_estimators=400)\n",
        "# ye wala max hai jo use hua bsdk\n",
        "\n",
        "# # 1\n",
        "\n",
        "\n",
        "# # 2\n",
        "# model = RandomForestClassifier(max_depth=15, min_samples_split=10, n_estimators=200)\n",
        "\n",
        "# # 3\n",
        "# model = RandomForestClassifier(max_depth=20, min_samples_split=15, n_estimators=300)\n",
        "\n",
        "# # 4\n",
        "# model = RandomForestClassifier(max_depth=25, min_samples_split=20, n_estimators=400)\n",
        "\n",
        "# # 5\n",
        "# model = RandomForestClassifier(max_depth=30, min_samples_split=25, n_estimators=500)\n",
        "\n",
        "# # 6\n",
        "# model = RandomForestClassifier(max_depth=35, min_samples_split=30, n_estimators=600)\n",
        "\n",
        "# # 7\n",
        "# model = RandomForestClassifier(max_depth=40, min_samples_split=35, n_estimators=700)\n",
        "\n",
        "# # 8\n",
        "# model = RandomForestClassifier(max_depth=45, min_samples_split=40, n_estimators=800)\n",
        "\n",
        "# # 9\n",
        "# model = RandomForestClassifier(max_depth=50, min_samples_split=45, n_estimators=900)\n",
        "\n",
        "# # 10\n",
        "# model = RandomForestClassifier(max_depth=55, min_samples_split=50, n_estimators=1000)\n",
        "\n",
        "# # 11\n",
        "# model = RandomForestClassifier(max_depth=60, min_samples_split=55, n_estimators=1100)\n",
        "\n",
        "# # 12\n",
        "# model = RandomForestClassifier(max_depth=65, min_samples_split=60, n_estimators=1200)\n",
        "\n",
        "# # 13\n",
        "# model = RandomForestClassifier(max_depth=70, min_samples_split=65, n_estimators=1300)\n",
        "\n",
        "# # 14\n",
        "# model = RandomForestClassifier(max_depth=75, min_samples_split=70, n_estimators=1400)\n",
        "\n",
        "# # 15\n",
        "# model = RandomForestClassifier(max_depth=80, min_samples_split=75, n_estimators=1500)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#0.97 for max_depth=22,min_samples_split=2,n_estimators=400\n",
        "# 0.965 model = RandomForestClassifier(max_depth=21,min_samples_split=3,n_estimators=350)\n",
        "# model = KNeighborsClassifier(n_neighbors=11)\n",
        "\n",
        "# model = svm.SVC( C=1.0)\n",
        "\n",
        "# # Model 2: SVM with RBF Kernel and C=1.0\n",
        "model = SVC(kernel='rbf', C=5.0)\n",
        "\n",
        "# # Model 3: SVM with Polynomial Kernel, C=1.0, and Degree=2\n",
        "# model = SVC(kernel='poly', C=1.0, degree=2)\n",
        "\n",
        "# # Model 4: SVM with Sigmoid Kernel, C=1.0, and Coef0=0.0\n",
        "# model = SVC(kernel='sigmoid', C=1.0, coef0=0.0)\n",
        "\n",
        "# # Model 5: SVM with Linear Kernel and C=0.5\n",
        "# model5 = SVC(kernel='linear', C=0.5)\n",
        "model.fit(X,Y)\n",
        "\n",
        "# I will use library to get a accuracy score and f1 score which will help me decide the best model to use\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# print(\"test ki acc and f1 \",\"\\n\")\n",
        "y_pred = model.predict(X_val)\n",
        "val_acc = accuracy_score(y_val,y_pred)\n",
        "val_f1 = f1_score(y_val,y_pred,average='macro')\n",
        "print(\"Training Accuracy :\",val_acc, \"\\\\\\\\\")\n",
        "#print(\"Training f1 Score:\",val_f1)\n",
        "# print(val_acc)\n",
        "# print('\\n')\n",
        "# print(val_f1)\n",
        "\n",
        "# print(\"train ki acc and f1 \",\"\\n\")\n",
        "y_pred = model.predict(X_train)\n",
        "val_acc = accuracy_score(y_train,y_pred)\n",
        "val_f1 = f1_score(y_train,y_pred,average='macro')\n",
        "print(\"Testing Accuracy :\",val_acc, \"\\\\\\\\\")\n",
        "print(\"Testing f1 Score:\",val_f1)\n",
        "# print(val_acc)\n",
        "# print('\\n')\n",
        "# print(val_f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKWIYvy5zu3l",
        "outputId": "c1ecff7c-e550-4f5a-f072-dd517963c8b2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy : 0.26796116504854367 \\\\\n",
            "Testing Accuracy : 0.2603626943005181 \\\\\n",
            "Testing f1 Score: 0.05293342558683114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ab chaalu testing code\n",
        "testing_features=['Party', 'Criminal Case', 'Total Assets', 'Liabilities', 'state']\n",
        "test_columns_to_encode = ['Party', 'state']\n",
        "# as ID and name are different for all there is no point inculding that to predict education\n",
        "Xtest=test_df[testing_features]\n",
        "\n",
        "label_encoder_test = {}\n",
        "# different encoder to maintain consistency in encoding and prevents data leakage\n",
        "\n",
        "for col in test_columns_to_encode:\n",
        "    label_encoder_test[col] = LabelEncoder()\n",
        "    test_df[col + '_encoded_into_numeric'] = label_encoder_test[col].fit_transform(test_df[col])\n",
        "#encoded and non-encoded columns\n",
        "test_encoded_columns = [col + '_encoded_into_numeric' for col in test_columns_to_encode]\n",
        "test_not_encoded_columns = [col for col in testing_features if col not in test_columns_to_encode]\n",
        "Xtest = test_df[test_not_encoded_columns + test_encoded_columns]\n",
        "#replacing colums with entire numerical value\n",
        "Xtest['Total Assets'] = Xtest['Total Assets'].apply(extract_numerical_value)\n",
        "Xtest['Liabilities']=Xtest['Liabilities'].apply(extract_numerical_value)"
      ],
      "metadata": {
        "id": "9k8TXbCkq8Kw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "guess=model.predict(Xtest)\n",
        "answers=label_encoder.inverse_transform(guess)\n",
        "#this code segment is making predictions (guess) on data (Xtest) using a trained machine learning model{knn ,rf ,svm,svc} (model)\n",
        "#then, it converts these predicted numerical labels back into their original categorical form (answers) using the LabelEncoder\n",
        "# here the same label_encoder is used which was first used to convert to numeral for better analysis"
      ],
      "metadata": {
        "id": "u84gLD-Obf89"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_answers_2= pd.DataFrame({'ID':test_df['ID'],'Education': answers})\n",
        "final_answers_2.to_csv('final_answers_returned14a.csv',index=False)\n",
        "\n",
        "# this code segment creates a DataFrame (final_answers_2) containing the 'ID' column from the test dataset (test_df['ID']) and the predicted education levels (answers).\n",
        "#Then, it saves this DataFrame to a CSV file named 'final_answers_returned14a.csv' without including the index column."
      ],
      "metadata": {
        "id": "kS6VVUEEcYl_"
      },
      "execution_count": 30,
      "outputs": []
    }
  ]
}